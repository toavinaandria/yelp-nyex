{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-17T09:14:33.814306",
     "start_time": "2017-01-17T09:14:33.810838"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import _pickle\n",
    "from os.path import join\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-17T09:14:34.229893",
     "start_time": "2017-01-17T09:14:34.227238"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tqdm.pandas(tqdm_notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-17T09:16:08.546430",
     "start_time": "2017-01-17T09:14:34.677477"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1 . Variables\n",
    "# --------------\n",
    "\n",
    "input_folder = 'raw_data'\n",
    "save_folder = join('pickles','3.agg_dfs')\n",
    "\n",
    "business_data_inputpath = join(input_folder,'yelp_academic_dataset_business.json')\n",
    "checkin_data_inputpath = join(input_folder,'yelp_academic_dataset_checkin.json')\n",
    "tip_data_inputpath = join(input_folder,'yelp_academic_dataset_tip.json')\n",
    "user_data_inputpath = join(input_folder,'yelp_academic_dataset_user.json')\n",
    "photo_data_inputpath = join(input_folder,'photo_id_to_business_id.json')\n",
    "\n",
    "\n",
    "# 2. Load dataframes\n",
    "# -------------------\n",
    "\n",
    "business_data = pd.read_json(business_data_inputpath,lines=True)\n",
    "checkin_data = pd.read_json(checkin_data_inputpath,lines=True)\n",
    "tip_data = pd.read_json(tip_data_inputpath,lines=True)\n",
    "user_data = pd.read_json(user_data_inputpath,lines=True)\n",
    "photo_data = pd.read_json(photo_data_inputpath,lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-11T22:47:21.287032",
     "start_time": "2017-01-11T22:47:21.033678"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3. Define functions\n",
    "# -------------------\n",
    "\n",
    "\n",
    "def convert_to_small_int(df,columns):\n",
    "    \"\"\"Converts dataframe column to small integers\"\"\"\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype('uint8')\n",
    "    return df\n",
    "\n",
    "\n",
    "def amend_business_data(df):\n",
    "    \"\"\"\n",
    "    Changes type for the business dataset to reduce memory use\n",
    "    Explodes attributes\n",
    "    Explodes hours\n",
    "    \"\"\"\n",
    "    # Change types to reduce memory usage\n",
    "    # -----------------------------------\n",
    "    \n",
    "    df = convert_to_small_int(df,['review_count'])\n",
    "    df['stars'] = df['stars'].astype('float32')\n",
    "    df.drop('type', axis=1, inplace=True)\n",
    "    df['state'] = df['state'].astype('category')\n",
    "    \n",
    "    \n",
    "    # Explode attributes\n",
    "    # -------------------\n",
    "    \n",
    "    attributes = df['attributes'].progress_apply(pd.Series)\n",
    "    df = pd.concat([df,attributes], axis=1)\n",
    "    \n",
    "    \n",
    "    # Explode hours\n",
    "    # --------------\n",
    "    \n",
    "    hours = df['hours'].progress_apply(pd.Series)\n",
    "    hours = hours.rename(columns = {'Friday': 'hours_Friday',\n",
    "                        'Monday': 'hours_Monday',\n",
    "                        'Saturday': 'hours_Saturday',\n",
    "                        'Sunday': 'hours_Sunday',\n",
    "                        'Thursday': 'hours_Thursday',\n",
    "                        'Tuesday': 'hours_Tuesday',\n",
    "                        'Wednesday': 'hours_Wednesday'\n",
    "                       })\n",
    "    df = pd.concat([df,hours],axis=1)\n",
    "    \n",
    "    # Note - Leaving categories as is because there are over 1,000 unique categories\n",
    "    return df    \n",
    "\n",
    "\n",
    "def amend_checkin_data(df):\n",
    "    \"\"\"Explodes checkin info\"\"\"\n",
    "    checkin = df['checkin_info'].progress_apply(pd.Series)\n",
    "    df = pd.concat([df,checkin],axis=1)\n",
    "    df.drop('type',axis=1,inplace=True)\n",
    "    del checkin\n",
    "    return df\n",
    "\n",
    "\n",
    "def amend_tip_data(df):\n",
    "    \"\"\"Changes types for tip data\"\"\"\n",
    "    df['likes'] = df['likes'].astype('uint8')\n",
    "    df.drop('type',axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def amend_photo_data(df):\n",
    "    \"\"\"Amends the photo dataset to reduce memory usage and transpose it properly\"\"\"\n",
    "    photodata = df.transpose()[0].progress_apply(pd.Series)\n",
    "    photodata['label'] = photodata['label'].astype('category')\n",
    "    return photodata\n",
    "\n",
    "\n",
    "def amend_user_data(df):\n",
    "    \"\"\"Amends user data dataframe to extract features and reduce memory usage\"\"\"\n",
    "    \n",
    "    # Explode compliments\n",
    "    # --------------------\n",
    "    \n",
    "    compliments = df.compliments.progress_apply(pd.Series)\n",
    "    \n",
    "    # Add prefix to compliments column name\n",
    "    compliments = compliments.rename(columns={key:'compliment_{}'.format(key) for key in compliments.columns.values})\n",
    "    \n",
    "    df = pd.concat([df,compliments], axis=1)\n",
    "    \n",
    "    del compliments\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    # Amend types\n",
    "    # ------------\n",
    "    \n",
    "    df.average_stars = df.average_stars.astype('float32')\n",
    "    df.fans = df.fans.astype('uint16')\n",
    "    df.review_count = df.review_count.astype('uint16')\n",
    "    df.yelping_since = df.yelping_since.astype('datetime64')\n",
    "    \n",
    "    \n",
    "    # TODO - If important at some point, explode elite and extract features\n",
    "    \n",
    "    \n",
    "    # Extract number of friends\n",
    "    # -------------------------\n",
    "    \n",
    "    df['num_friends'] = df.friends.apply(len)\n",
    "    df['num_friends'] = df['num_friends'].astype('uint16')\n",
    "    \n",
    "    \n",
    "    # Drop type column\n",
    "    # ----------------\n",
    "    \n",
    "    df.drop('type',axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    # Explode votes\n",
    "    # --------------\n",
    "    \n",
    "    votes = df.votes.progress_apply(pd.Series)\n",
    "    # Add prefix to column name to identify votes\n",
    "    votes = votes.rename(columns={key:'votes_{}'.format(key) for key in votes.columns.values})\n",
    "    votes = votes.astype('uint32')\n",
    "    \n",
    "    df = pd.concat([df,votes], axis=1)\n",
    "    \n",
    "    \n",
    "    # Extracting Yelp tenure\n",
    "    # ----------------\n",
    "    \n",
    "    end_date = df.yelping_since.max()\n",
    "    df['yelp_tenure'] = pd.Series(end_date - df.yelping_since)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-11T20:59:11.564034",
     "start_time": "2017-01-11T20:58:09.119494"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85901/85901 [00:32<00:00, 2653.34it/s]\n",
      "100%|██████████| 85901/85901 [00:29<00:00, 2924.74it/s]\n"
     ]
    }
   ],
   "source": [
    "# 4. Run functions to amend data\n",
    "# ---------------------------\n",
    "\n",
    "business_data = amend_business_data(business_data)\n",
    "checkin_data = amend_checkin_data(checkin_data)\n",
    "tip_data = amend_tip_data(tip_data)\n",
    "photo_data = amend_photo_data(photo_data)\n",
    "user_data = amend_user_data(user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-01-11T22:52:07.914219",
     "start_time": "2017-01-11T22:51:37.280477"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 5. Pickle dataframes\n",
    "# ---------------------\n",
    "\n",
    "_pickle.dump(business_data,open(join(save_folder,'business_data.pkl'),'wb'))\n",
    "_pickle.dump(checkin_data,open(join(save_folder,'checkin_data.pkl'),'wb'))\n",
    "_pickle.dump(tip_data,open(join(save_folder,'tip_data.pkl'),'wb'))\n",
    "_pickle.dump(photo_data,open(join(save_folder,'photo_data.pkl'),'wb'))\n",
    "_pickle.dump(user_data,open(join(save_folder,'user_data.pkl'),'wb'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
